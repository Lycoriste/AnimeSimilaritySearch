{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borng/Documents/code/DataHacks/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the multilingual model\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anime_id(anime_name):\n",
    "    \"\"\"\n",
    "    Query the AniList API to find the anime ID for the given anime name.\n",
    "    \"\"\"\n",
    "    url = \"https://graphql.anilist.co\"\n",
    "    query = '''\n",
    "    query ($search: String) {\n",
    "      Media(search: $search, type: ANIME) {\n",
    "        id\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    variables = {'search': anime_name}\n",
    "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get('data', {}).get('Media', {}).get('id', None)\n",
    "    else:\n",
    "        print(\"Error querying AniList API for ID\")\n",
    "        return None\n",
    "\n",
    "def get_anime_name(anime_id):\n",
    "    \"\"\"\n",
    "    Query the AniList API to get the anime name given an anime id.\n",
    "    Convert the anime_id to a standard Python int to avoid JSON serialization issues.\n",
    "    \"\"\"\n",
    "    url = \"https://graphql.anilist.co\"\n",
    "    query = '''\n",
    "    query ($id: Int) {\n",
    "      Media(id: $id, type: ANIME) {\n",
    "        title {\n",
    "          romaji\n",
    "          english\n",
    "          native\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    variables = {'id': int(anime_id)}  # Convert to Python int to ensure JSON serialization\n",
    "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        title_info = data.get('data', {}).get('Media', {}).get('title', {})\n",
    "        # Prefer English title if available, else romaji, then native\n",
    "        anime_name = title_info.get('english') or title_info.get('romaji') or title_info.get('native')\n",
    "        return anime_name\n",
    "    else:\n",
    "        print(\"Error querying AniList API for anime name\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the review to make recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed review embeddings...\n",
      "\n",
      "Top 20 similar anime to 'attack on titan' (Anime id 16498):\n",
      "Attack on Titan Final Season (ID: 110277) - Similarity: 89.84\n",
      "Attack on Titan Season 3 Part 2 (ID: 104578) - Similarity: 89.23\n",
      "Attack on Titan Season 3 (ID: 99147) - Similarity: 88.16\n",
      "JoJo's Bizarre Adventure (TV) (ID: 14719) - Similarity: 87.93\n",
      "Vinland Saga (ID: 101348) - Similarity: 87.91\n",
      "Fullmetal Alchemist: Brotherhood (ID: 5114) - Similarity: 87.82\n",
      "Tokyo Ghoul (ID: 20605) - Similarity: 87.48\n",
      "Hunter x Hunter (2011) (ID: 11061) - Similarity: 87.44\n",
      "Attack on Titan Final Season THE FINAL CHAPTERS Special 2 (ID: 162314) - Similarity: 87.38\n",
      "Attack on Titan Season 2 (ID: 20958) - Similarity: 87.04\n",
      "Steins;Gate (ID: 9253) - Similarity: 86.92\n",
      "Attack on Titan Final Season THE FINAL CHAPTERS Special 1 (ID: 146984) - Similarity: 86.20\n",
      "The Promised Neverland (ID: 101759) - Similarity: 86.02\n",
      "Neon Genesis Evangelion (ID: 30) - Similarity: 85.96\n",
      "Black Clover (ID: 97940) - Similarity: 85.89\n",
      "Assassination Classroom 2 (ID: 21170) - Similarity: 85.89\n",
      "ONE PIECE (ID: 21) - Similarity: 85.89\n",
      "Berserk (ID: 33) - Similarity: 85.88\n",
      "Daily Lives of High School Boys (ID: 11843) - Similarity: 85.86\n",
      "Error querying AniList API for anime name\n",
      "Anime ID 101921 - Similarity: 85.82 (Name not found)\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame which has columns: anime_id and top_review\n",
    "df = pd.read_csv('./data/data.csv')\n",
    "\n",
    "\n",
    "# Pre-compute or load review embeddings\n",
    "embedding_file = './data/review_embeddings.pt'\n",
    "review_texts = df['top_review'].tolist()\n",
    "\n",
    "if os.path.exists(embedding_file):\n",
    "    print(\"Loading pre-computed review embeddings...\")\n",
    "    review_embeddings = torch.load(embedding_file)\n",
    "else:\n",
    "    print(\"Computing review embeddings...\")\n",
    "    review_embeddings = model.encode(review_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    torch.save(review_embeddings, embedding_file)\n",
    "\n",
    "# Prompt the user for an anime name\n",
    "user_anime = input(\"Enter an anime name: \")\n",
    "\n",
    "# Use AniList API to get the anime id for the given anime name\n",
    "anime_id = get_anime_id(user_anime)\n",
    "if anime_id is None:\n",
    "    print(f\"Anime '{user_anime}' not found on AniList.\")\n",
    "else:\n",
    "    # Check if the anime id exists in the DataFrame\n",
    "    if anime_id not in df['anime_id'].values:\n",
    "        print(f\"Anime '{user_anime}' with id {anime_id} not found in the dataframe.\")\n",
    "    else:\n",
    "        # Get the index and review corresponding to the anime_id in the DataFrame\n",
    "        selected_index = df.index[df['anime_id'] == anime_id][0]\n",
    "        query_review = df.loc[selected_index, 'top_review']\n",
    "        \n",
    "        # Encode the review for the selected anime\n",
    "        query_embedding = model.encode([query_review], convert_to_tensor=True, normalize_embeddings=True)\n",
    "        \n",
    "        # Compute cosine similarity scores between the selected review and all other reviews\n",
    "        scores = (query_embedding @ review_embeddings.T) * 100  # cosine similarity scaled by 100\n",
    "        scores_list = scores.tolist()[0]\n",
    "        \n",
    "        # Prepare similarity results, excluding the selected anime itself\n",
    "        similarity_results = []\n",
    "        for idx, score in enumerate(scores_list):\n",
    "            if idx != selected_index:\n",
    "                similarity_results.append((df.loc[idx, 'anime_id'], score))\n",
    "        \n",
    "        # Sort the results by similarity score in descending order\n",
    "        similarity_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get the top 20 most similar anime and use the API to get their names\n",
    "        top_20 = similarity_results[:20]\n",
    "        print(f\"\\nTop 20 similar anime to '{user_anime}' (Anime id {anime_id}):\")\n",
    "        for other_anime_id, score in top_20:\n",
    "            anime_name_result = get_anime_name(other_anime_id)\n",
    "            if anime_name_result:\n",
    "                print(f\"{anime_name_result} (ID: {other_anime_id}) - Similarity: {score:.2f}\")\n",
    "            else:\n",
    "                print(f\"Anime ID {other_anime_id} - Similarity: {score:.2f} (Name not found)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using description to make recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing description embeddings...\n",
      "\n",
      "Top 20 similar anime to 'attack on titan' (Anime id 16498):\n",
      "Attack on Titan Season 2 (ID: 20958) - Similarity: 91.52\n",
      "Attack on Titan Final Season THE FINAL CHAPTERS Special 1 (ID: 146984) - Similarity: 89.61\n",
      "Tokyo Revengers (ID: 120120) - Similarity: 89.53\n",
      "Attack on Titan Final Season THE FINAL CHAPTERS Special 2 (ID: 162314) - Similarity: 88.81\n",
      "Demon Slayer: Kimetsu no Yaiba (ID: 101922) - Similarity: 88.69\n",
      "Attack on Titan: No Regrets (ID: 20811) - Similarity: 88.66\n",
      "Attack on Titan Final Season (ID: 110277) - Similarity: 88.32\n",
      "DARLING in the FRANXX (ID: 99423) - Similarity: 87.98\n",
      "Attack on Titan Season 3 Part 2 (ID: 104578) - Similarity: 87.85\n",
      "Dr. STONE (ID: 105333) - Similarity: 87.60\n",
      "ALDNOAH.ZERO (ID: 20632) - Similarity: 87.43\n",
      "A Lull in the Sea (Nagi-Asu: Nagi no Asukara) (ID: 16067) - Similarity: 87.31\n",
      "God Eater (ID: 20849) - Similarity: 87.21\n",
      "Record of Ragnarok (ID: 127399) - Similarity: 87.16\n",
      "Haibane Renmei (ID: 387) - Similarity: 87.12\n",
      "The World's Finest Assassin Gets Reincarnated in Another World as an Aristocrat (ID: 129898) - Similarity: 87.08\n",
      "Plastic Memories (ID: 20872) - Similarity: 87.05\n",
      "Chainsaw Man (ID: 127230) - Similarity: 87.02\n",
      "Code Geass: Lelouch of the Re;surrection (ID: 97880) - Similarity: 87.02\n",
      "World Trigger (ID: 20729) - Similarity: 86.97\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame which has columns: anime_id and description\n",
    "df = pd.read_csv('./data/desc_data.csv')\n",
    "\n",
    "\n",
    "# Pre-compute or load review embeddings\n",
    "embedding_file = './data/review_embeddings2.pt'\n",
    "review_texts = df['description'].tolist()\n",
    "\n",
    "if os.path.exists(embedding_file):\n",
    "    print(\"Loading pre-computed description embeddings...\")\n",
    "    review_embeddings = torch.load(embedding_file)\n",
    "else:\n",
    "    print(\"Computing description embeddings...\")\n",
    "    review_embeddings = model.encode(review_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    torch.save(review_embeddings, embedding_file)\n",
    "\n",
    "# Prompt the user for an anime name\n",
    "user_anime = input(\"Enter an anime name: \")\n",
    "\n",
    "# Use AniList API to get the anime id for the given anime name\n",
    "anime_id = get_anime_id(user_anime)\n",
    "if anime_id is None:\n",
    "    print(f\"Anime '{user_anime}' not found on AniList.\")\n",
    "else:\n",
    "    # Check if the anime id exists in the DataFrame\n",
    "    if anime_id not in df['anime_id'].values:\n",
    "        print(f\"Anime '{user_anime}' with id {anime_id} not found in the dataframe.\")\n",
    "    else:\n",
    "        # Get the index and review corresponding to the anime_id in the DataFrame\n",
    "        selected_index = df.index[df['anime_id'] == anime_id][0]\n",
    "        query_review = df.loc[selected_index, 'description']\n",
    "        \n",
    "        # Encode the review for the selected anime\n",
    "        query_embedding = model.encode([query_review], convert_to_tensor=True, normalize_embeddings=True)\n",
    "        \n",
    "        # Compute cosine similarity scores between the selected review and all other reviews\n",
    "        scores = (query_embedding @ review_embeddings.T) * 100  # cosine similarity scaled by 100\n",
    "        scores_list = scores.tolist()[0]\n",
    "        \n",
    "        # Prepare similarity results, excluding the selected anime itself\n",
    "        similarity_results = []\n",
    "        for idx, score in enumerate(scores_list):\n",
    "            if idx != selected_index:\n",
    "                similarity_results.append((df.loc[idx, 'anime_id'], score))\n",
    "        \n",
    "        # Sort the results by similarity score in descending order\n",
    "        similarity_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get the top 20 most similar anime and use the API to get their names\n",
    "        top_20 = similarity_results[:20]\n",
    "        print(f\"\\nTop 20 similar anime to '{user_anime}' (Anime id {anime_id}):\")\n",
    "        for other_anime_id, score in top_20:\n",
    "            anime_name_result = get_anime_name(other_anime_id)\n",
    "            if anime_name_result:\n",
    "                print(f\"{anime_name_result} (ID: {other_anime_id}) - Similarity: {score:.2f}\")\n",
    "            else:\n",
    "                print(f\"Anime ID {other_anime_id} - Similarity: {score:.2f} (Name not found)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Remove the model reference\n",
    "del model\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# If you're using GPU, you can free unused GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
